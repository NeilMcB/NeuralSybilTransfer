{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup latex formatting\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "rc('font', family='serif', size=28)\n",
    "rc('axes', labelsize=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_DIM = 512  # limit images to MAX_DIM x MAX_DIM resolution\n",
    "MAX_RGB = 255  #Â maximum RGB intensize\n",
    "\n",
    "VGG19_INPUT_SHAPE = (224, 224)  # shape of input taken by VV19\n",
    "\n",
    "content_path = 'images/in/sybil.jpg'  # location of content image\n",
    "style_path = 'images/in/cezanne_style.jpg'  # location of style image\n",
    "\n",
    "# for matching features in generated image to content and style images\n",
    "content_layers = ['block5_conv2']\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "                'block5_conv1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    \"\"\" Load and resize image.\n",
    "    \n",
    "    Load image from the specified path into a tensor and resize to\n",
    "    safely propagate through network.\n",
    "    \n",
    "    Args:\n",
    "        path (str): path to image\n",
    "        \n",
    "    Returns:\n",
    "        img (tf.Tensor): tensor representing image with max size\n",
    "            (1, MAX_DIM, MAX_DIM, 3)\n",
    "    \"\"\"\n",
    "    img = tf.read_file(path)\n",
    "    img = tf.cond(tf.image.is_jpeg(img),\n",
    "                  lambda: tf.image.decode_jpeg(img, channels=3),\n",
    "                  lambda: tf.image.decode_png(img, channels=3))\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # determine scaling to reduce to MAX_DIM\n",
    "    orig_shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "    long_dim = tf.reduce_max(orig_shape)\n",
    "    scale = MAX_DIM / long_dim\n",
    "    # cast into new shape ()\n",
    "    scaled_shape = tf.cast(orig_shape * scale, tf.int32)\n",
    "    img = tf.image.resize(img, scaled_shape)\n",
    "    img = img[tf.newaxis, :]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_img = load_img(content_path)\n",
    "style_img = load_img(style_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_intermediate_output(layer_names):\n",
    "    \"\"\" Create pretrained VGG model with intermediate outputs.\n",
    "    \n",
    "    Load the pretrained VGG network and construct a model which outputs\n",
    "    from intermediate layers.\n",
    "    \n",
    "    Args:\n",
    "        layer_names (list): list of layer names to output from.\n",
    "        \n",
    "    Returns:\n",
    "        model (tf.keras.Model): the corresponding model\n",
    "    \"\"\"\n",
    "    # include_top=False -> no classification layer\n",
    "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    \n",
    "    outputs = [vgg.get_layer(name).output for name in layer_names]\n",
    "    \n",
    "    model = tf.keras.Model([vgg.input], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0710 12:14:20.048684 4583912896 deprecation.py:506] From /anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "style_model = vgg_intermediate_output(style_layers)\n",
    "style_outputs = style_model(style_img*MAX_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gram_matrix(input_tensor):\n",
    "    \"\"\" Compute the normalised Gram matrix.\n",
    "    \n",
    "    Takes a batch (b) of matrices with and computes the Gram matrix for each.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor (tf.Tensor): Tensor containing batch of matrices.\n",
    "    \"\"\"\n",
    "    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "    input_shape = tf.shape(input_tensor)\n",
    "    n_elems = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
    "    return result/n_elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StyleContentModel(tf.keras.models.Model):\n",
    "    \"\"\" A model which returns the style and content tensors of an image.\n",
    "    \"\"\"\n",
    "    def __init__(self, style_laters, content_layers):\n",
    "        \"\"\" Create pretrained VGG model with intermediate layer outputs.\n",
    "        \n",
    "        Args:\n",
    "            style_layers (list): Names of intermediate VGG layers to \n",
    "                extract style outputs from.\n",
    "            content_layers (list): Names of intermediate VGG layers to \n",
    "                extract content outputs from.\n",
    "        \"\"\"\n",
    "        super(StyleContentModel, self).__init__()\n",
    "        self.vgg = vgg_intermediate_output(style_layers + content_layers)\n",
    "        self.style_layers = style_layers\n",
    "        self.content_layers = content_layers\n",
    "        self.num_style_layers = len(style_layers)\n",
    "        self.vgg.trainable = False\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \"\"\" Extract the content and style outputs for a given input.\n",
    "        \n",
    "        Given an image, preprocess and pass to the pretrained VGG19 network. \n",
    "        Extract and neatly package the style and content outputs.\n",
    "        \n",
    "        Args:\n",
    "            inputs (tf.Tensor): (Batch of) input image(s) with pixel values in\n",
    "                range (0,1).\n",
    "        \n",
    "        Returns:\n",
    "            cache (dict): Neatly packaged cache of style and content outputs.\n",
    "        \"\"\"\n",
    "        inputs = inputs*MAX_RGB\n",
    "        preprocessed_inputs = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
    "        outputs = self.vgg(preprocessed_inputs)\n",
    "        style_outputs, content_outputs = (outputs[:self.num_style_layers],\n",
    "                                          outputs[self.num_style_layers:])\n",
    "        \n",
    "        style_outputs = [compute_gram_matrix(style_output)\n",
    "                         for style_output in style_outputs]\n",
    "        \n",
    "        content_dict = {content_name : value\n",
    "                        for content_name, value\n",
    "                        in zip(self.content_layers, content_outputs)}\n",
    "        \n",
    "        style_dict = {style_name : value\n",
    "                      for style_name, value\n",
    "                      in zip(self.style_layers, style_outputs)}\n",
    "        \n",
    "        cache = {'content' : content_dict, 'style' : style_dict} \n",
    "        return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extractor = StyleContentModel(style_layers, content_layers)\n",
    "results = extractor(content_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_11:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_content_loss(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_targets = extractor(style_img)['style']\n",
    "content_targets = extractor(content_img)['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_starting_img(content_img):\n",
    "    img = tf.Variable(tf.random.uniform((1, VGG19_INPUT_SHAPE[0], VGG19_INPUT_SHAPE[1], 3)))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = create_starting_img(content_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clip(img, lo=0., hi=1.):\n",
    "    return tf.clip_by_value(img, clip_value_min=lo, clip_value_max=hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(learning_rate=0.02, beta1=0.99, epsilon=1e-1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def style_content_loss(outputs, style_weight=1e-2, content_weight=1e5):\n",
    "    \"\"\" Compute the weighted loss of the given outputs.\n",
    "    \"\"\"\n",
    "    style_outputs = outputs['style']\n",
    "    content_outputs = outputs['content']\n",
    "    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name] - style_targets[name])**2)\n",
    "                           for name in style_outputs.keys()])\n",
    "    style_loss *= style_weight / len(style_outputs)\n",
    "    \n",
    "    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name] - content_targets[name])**2)\n",
    "                             for name in content_outputs.keys()])\n",
    "    content_loss *= content_weight / len(content_outputs)\n",
    "    \n",
    "    loss = style_loss + content_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def high_pass_x_y(img):\n",
    "    x_var = img[:,:,1:,:] - img[:,:,:-1,:]\n",
    "    y_var = img[:,1:,:,:] - img[:,:-1,:,:]\n",
    "    return x_var, y_var\n",
    "\n",
    "def total_variational_loss(img):\n",
    "    x_deltas, y_deltas = high_pass_x_y(img)\n",
    "    return tf.reduce_mean(x_deltas**2) + tf.reduce_mean(y_deltas**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(img, total_variational_weight=1e8):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = extractor(img)\n",
    "        loss = style_content_loss(outputs)\n",
    "        loss += total_variational_weight*total_variational_loss(img)\n",
    "    \n",
    "        grad = tape.gradient(loss, img)\n",
    "        opt.apply_gradients([(grad, img)])\n",
    "        img.assign(clip(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_and_save_images(content_img, combined_img, style_img, img_name=None, img_base='images/out/'):\n",
    "    # plot\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18,6))\n",
    "    plot_img(axs[0], content_img, 'Content Image')\n",
    "    plot_img(axs[1], combined_img, 'Combined')\n",
    "    plot_img(axs[2], style_img, 'Style Image')\n",
    "    # format\n",
    "    fig.tight_layout()\n",
    "    # save\n",
    "    if img_name is None:\n",
    "        img_path = img_base+\"combined.png\"\n",
    "    else:\n",
    "        img_path = img_base+img_name+\".png\"\n",
    "    fig.savefig(img_path, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "initial_value must have a shape specified: Tensor(\"strided_slice_1:0\", shape=(1, ?, ?, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-7e6fa3f13429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                         shape=None):\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2509\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2511\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m           shape=shape)\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1733\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minitial_value_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m             raise ValueError(\"initial_value must have a shape specified: %s\" %\n\u001b[0;32m-> 1735\u001b[0;31m                              self._initial_value)\n\u001b[0m\u001b[1;32m   1736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m         \u001b[0;31m# If 'initial_value' makes use of other variables, make sure we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: initial_value must have a shape specified: Tensor(\"strided_slice_1:0\", shape=(1, ?, ?, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "img = tf.Variable(content_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "steps_per_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [1,14,14,512] vs. [1,32,32,512]\n\t [[node gradients_7/sub_65_grad/BroadcastGradientArgs (defined at <ipython-input-54-89d529a9b26a>:1) ]]\n\nOriginal stack trace for 'gradients_7/sub_65_grad/BroadcastGradientArgs':\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-54-89d529a9b26a>\", line 1, in <module>\n    opt = tf.train.AdamOptimizer(learning_rate=0.02, beta1=0.99, epsilon=1e-1).minimize(loss)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 403, in minimize\n    grad_loss=grad_loss)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 512, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 158, in gradients\n    unconnected_gradients)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 731, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 403, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 731, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 1027, in _SubGrad\n    rx, ry = gen_array_ops.broadcast_gradient_args(sx, sy)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 829, in broadcast_gradient_args\n    \"BroadcastGradientArgs\", s0=s0, s1=s1, name=name)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'sub_65', defined at:\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 25 identical lines from previous traceback]\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-52-f3fd071bfa65>\", line 2, in <module>\n    loss = style_content_loss(outputs)\n  File \"<ipython-input-32-a4cd41947407>\", line 11, in style_content_loss\n    for name in content_outputs.keys()])\n  File \"<ipython-input-32-a4cd41947407>\", line 11, in <listcomp>\n    for name in content_outputs.keys()])\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 10855, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,14,14,512] vs. [1,32,32,512]\n\t [[{{node gradients_7/sub_65_grad/BroadcastGradientArgs}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-01bb294e7a3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,14,14,512] vs. [1,32,32,512]\n\t [[node gradients_7/sub_65_grad/BroadcastGradientArgs (defined at <ipython-input-54-89d529a9b26a>:1) ]]\n\nOriginal stack trace for 'gradients_7/sub_65_grad/BroadcastGradientArgs':\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-54-89d529a9b26a>\", line 1, in <module>\n    opt = tf.train.AdamOptimizer(learning_rate=0.02, beta1=0.99, epsilon=1e-1).minimize(loss)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 403, in minimize\n    grad_loss=grad_loss)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 512, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 158, in gradients\n    unconnected_gradients)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 731, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 403, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 731, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 1027, in _SubGrad\n    rx, ry = gen_array_ops.broadcast_gradient_args(sx, sy)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 829, in broadcast_gradient_args\n    \"BroadcastGradientArgs\", s0=s0, s1=s1, name=name)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'sub_65', defined at:\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 25 identical lines from previous traceback]\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-52-f3fd071bfa65>\", line 2, in <module>\n    loss = style_content_loss(outputs)\n  File \"<ipython-input-32-a4cd41947407>\", line 11, in style_content_loss\n    for name in content_outputs.keys()])\n  File \"<ipython-input-32-a4cd41947407>\", line 11, in <listcomp>\n    for name in content_outputs.keys()])\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 10855, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    for n in range(epochs):\n",
    "        for m in range(steps_per_epoch):\n",
    "            step += 1\n",
    "            _, c = sess.run([opt, loss])\n",
    "            print(\".\", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfig, axs = plt.subplots(1, 3, figsize=(18,6))\\naxs[0].imshow(tf.squeeze(content_img, axis=0))\\naxs[1].imshow(tf.squeeze(style_img, axis=0))\\naxs[2].imshow(img.read_value()[0])\\naxs[0].axis('off')\\naxs[1].axis('off')\\naxs[2].axis('off')\\naxs[0].set_title('Content Image')\\naxs[1].set_title('Style Image')\\naxs[2].set_title('Combined')\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18,6))\n",
    "axs[0].imshow(tf.squeeze(content_img, axis=0))\n",
    "axs[1].imshow(tf.squeeze(style_img, axis=0))\n",
    "axs[2].imshow(img.read_value()[0])\n",
    "axs[0].axis('off')\n",
    "axs[1].axis('off')\n",
    "axs[2].axis('off')\n",
    "axs[0].set_title('Content Image')\n",
    "axs[1].set_title('Style Image')\n",
    "axs[2].set_title('Combined')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in range(0,2001,50)[1:]:\n",
    "    path = 'images/out/gif/combined_%d.png'%i\n",
    "    images.append(imageio.imread(path))\n",
    "for i in range(50):\n",
    "    images.append(imageio.imread(path))\n",
    "imageio.mimsave('images/out/process.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpimg.imsave('images/out/sybil_2000_steps.png', tf.squeeze(img, axis=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 512, 512, 3) dtype=float32, numpy=\n",
       "array([[[[0.4853375 , 0.4070687 , 0.21224578],\n",
       "         [0.49325696, 0.40537363, 0.21416649],\n",
       "         [0.51216877, 0.4325639 , 0.24133198],\n",
       "         ...,\n",
       "         [0.47865784, 0.5217105 , 0.21765208],\n",
       "         [0.5125218 , 0.55106246, 0.2146284 ],\n",
       "         [0.5138633 , 0.5584453 , 0.20674834]],\n",
       "\n",
       "        [[0.47624263, 0.41051453, 0.21441986],\n",
       "         [0.49277648, 0.4262772 , 0.23299034],\n",
       "         [0.5095588 , 0.4595523 , 0.26200613],\n",
       "         ...,\n",
       "         [0.45522287, 0.5151871 , 0.23813616],\n",
       "         [0.47685027, 0.5265361 , 0.21656656],\n",
       "         [0.485423  , 0.5214637 , 0.1871035 ]],\n",
       "\n",
       "        [[0.45382747, 0.43344113, 0.23642102],\n",
       "         [0.46725896, 0.45505232, 0.26318938],\n",
       "         [0.47213545, 0.4838665 , 0.2890054 ],\n",
       "         ...,\n",
       "         [0.43371195, 0.5052511 , 0.27371216],\n",
       "         [0.44882444, 0.49998575, 0.223767  ],\n",
       "         [0.448546  , 0.48441616, 0.19247967]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.72896683, 0.49517253, 0.47156128],\n",
       "         [0.8076901 , 0.6502015 , 0.51340723],\n",
       "         [0.73764765, 0.7024312 , 0.5056239 ],\n",
       "         ...,\n",
       "         [0.6545408 , 0.4907999 , 0.30964088],\n",
       "         [0.68846965, 0.50996065, 0.3468961 ],\n",
       "         [0.7691397 , 0.5926962 , 0.42724365]],\n",
       "\n",
       "        [[0.9485816 , 0.75030535, 0.6820823 ],\n",
       "         [0.9291871 , 0.7574856 , 0.5811737 ],\n",
       "         [0.7500308 , 0.6831007 , 0.43646818],\n",
       "         ...,\n",
       "         [0.6504647 , 0.4783379 , 0.29122922],\n",
       "         [0.729791  , 0.5477822 , 0.38020808],\n",
       "         [0.80839986, 0.634113  , 0.4640298 ]],\n",
       "\n",
       "        [[1.        , 0.98301816, 0.80783147],\n",
       "         [0.9651592 , 0.8426584 , 0.6197741 ],\n",
       "         [0.69650614, 0.61457694, 0.36902   ],\n",
       "         ...,\n",
       "         [0.617374  , 0.44089448, 0.26058793],\n",
       "         [0.7490228 , 0.55025786, 0.39292637],\n",
       "         [0.8104174 , 0.6325465 , 0.45978534]]]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
